@echo off
rem =============================================================
rem  Vibe Coding ‚Äì One-Click Local Development Launcher (Windows)
rem  -----------------------------------------------------------
rem  Starts:
rem    ‚Ä¢ Qdrant vector DB (Docker Compose)
rem    ‚Ä¢ GPU-accelerated UMAP micro-service (Docker Compose, hot-reload)
rem    ‚Ä¢ Ingestion Orchestration FastAPI (host Python, hot-reload)
rem    ‚Ä¢ ML Inference FastAPI (host Python, hot-reload)
rem
rem  Requirements:
rem    1. Docker Desktop + WSL2 backend (for GPU passthrough)
rem    2. A Python ‚â•3.11 environment with project deps installed
rem       (e.g.  `pip install -r requirements.txt` from repo root).
rem =============================================================

:: Change to repo root (where this script lives)
cd /d "%~dp0.."

:: Make sure the shared Docker network exists
FOR /F "tokens=*" %%i IN ('docker network ls --filter name=^vibe_net$ --format "{{ .Name }}"') DO (
    SET network_exists=%%i
)
IF NOT DEFINED network_exists (
    echo Creating shared Docker network "vibe_net"...
    docker network create vibe_net
)

:: -------- 1Ô∏è‚É£  Qdrant DB -------------------------------------------------
ECHO.
ECHO Starting Qdrant vector DB...
Docker compose up -d qdrant_db || GOTO :error

:: -------- 2Ô∏è‚É£  GPU-UMAP micro-service -----------------------------------
ECHO.
ECHO Building & starting GPU-UMAP micro-service (hot-reload)...
Docker compose -f backend\gpu_umap_service\docker-compose.dev.yml up -d --build || GOTO :error

:: -------- 3Ô∏è‚É£  Ingestion Orchestration API --------------------------------
ECHO.
ECHO Launching Ingestion Orchestration FastAPI (port 8002)...
START "Ingestion API" cmd /k "python -m uvicorn backend.ingestion_orchestration_fastapi_app.main:app --host 0.0.0.0 --port 8002 --reload"

:: -------- 4Ô∏è‚É£  ML Inference API ------------------------------------------
ECHO.
ECHO Launching ML Inference FastAPI (port 8001)...
START "ML Inference API" cmd /k "python -m uvicorn backend.ml_inference_fastapi_app.main:app --host 0.0.0.0 --port 8001 --reload"

:: -------- 5Ô∏è‚É£  Frontend --------------------------------------------------
ECHO.
ECHO Launching Next.js frontend...
START "Frontend" cmd /k "cd frontend && npm run dev"

ECHO.
ECHO ‚úÖ All services are starting!   API Documentation:
ECHO   ‚Ä¢ http://localhost:8003/docs   (GPU UMAP - Docker)
ECHO   ‚Ä¢ http://localhost:8002/docs   (Ingestion Orchestration)
ECHO   ‚Ä¢ http://localhost:8001/docs   (ML Inference - Host Python)
ECHO.
ECHO üåê Frontend will auto-open at: http://localhost:3000
ECHO    Frontend auto-detects GPU UMAP (8003) or ML Inference (8001) services.
ECHO.
ECHO Press any key to close this launcher...
PAUSE
GOTO :eof

:error
ECHO.
ECHO ***** ERROR starting dev stack ‚Äì see messages above *****
PAUSE
exit /b 1 